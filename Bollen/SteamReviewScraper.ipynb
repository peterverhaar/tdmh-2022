{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c908fb",
   "metadata": {},
   "source": [
    "This following cell contains code for a script that crawls through a Steam game's reviews. It is supposed to use Selenium 4 to automatically open a Microsoft Edge webpage that then runs through the review section, grabbing each seperate \"card\" that contains a review. The review is sectioned off, prepped to be added to its own row, and each seperate element of the review is prepped to be added as seperate cells in a row in a csv file. The CSV file will look like the following: \n",
    "(Example review) \n",
    "\n",
    "\n",
    "| SteamId | ProfileURL | ReviewText | Review | ReviewLength(Chars) | PlayHours | DatePosted | \n",
    "|:------|:------|:------|:------|:------|:------|:------|\n",
    "| cadel13 | https://steamcommunity.com/id/cadel13/| Excellent flight game, feels so good to fly the classic star wars ships with all the lights and sound that accompany them. Highly recommend it | Recommended| 119| 14.3 | 14.3 hrs on record|\n",
    "\n",
    "However, I got this code from someone else's work, which uses a deprecated version of Selenium (Selenium 3), and I use Selenium 4. I believe I've updated the functions to match Selenium 4, but I am getting error after error. The current one is: \n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "<ipython-input-102-4f0e3dfab779> in <module>\n",
    "     31 while running:\n",
    "     32     # get cards on the page\n",
    "---> 33     cards = find_element(By.CLASS_NAME , \"apphub_Card\")\n",
    "     34 \n",
    "     35 for card in cards[-20]:   # only the tail end are new cards\n",
    "\n",
    "NameError: name 'find_element' is not defined\n",
    "    \n",
    "I imported selenium.webdriver.common.by By, and from what I understand it should work. \n",
    "    \n",
    "There's probably a ton of things wrong with this code, so if it is completely nonsensical then I will just go back to scraping reviews normally, which just takes longer. I also have the option of downloading datasets that have already been acquired from Kaggle, such as this one https://www.kaggle.com/datasets/najzeko/steam-reviews-2021 (that one contains 21 million reviews, so I will probably try and find a smaller dataset, this is just to serve as an example).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook\n",
    "import csv\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.relative_locator import locate_with\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "\n",
    "game_id = 1222730\n",
    "\n",
    "# get current position of y scrollbar\n",
    "last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "template = 'https://steamcommunity.com/app/{}/positivereviews/?browsefilter=mostrecent'\n",
    "template_with_language = 'https://steamcommunity.com/app/{}/positivereviews/?browsefilter=mostrecent&filterLanguage=english'\n",
    "\n",
    "url = template_with_language.format(game_id)\n",
    "\n",
    "reviews = []\n",
    "review_ids = set()\n",
    "running = True\n",
    "\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "while running:\n",
    "# get cards on the page\n",
    "    cards = card.find_element(By.CLASS_NAME , 'apphub_Card')\n",
    "# only the tail end are new cards\n",
    "for card in cards[-20]:   \n",
    "\n",
    "# gamer profile url\n",
    "    profile_url = card.find_element(By.XPATH , './/div[@class=\"apphub_friend_block\"]/div/a[2]').get_attribute('href')\n",
    "\n",
    "# steam id\n",
    "    steam_id = profile_url.split('/')[-2]\n",
    "        \n",
    "        # check to see if I've already collected this review\n",
    "if steam_id in review_ids:\n",
    "    continue\n",
    "else: review_ids.add(steam_id)\n",
    "\n",
    "        # username\n",
    "user_name = card.find_element(By.XPATH , './/div[@class=\"apphub_friend_block\"]/div/a[2]').text\n",
    "\n",
    "        # language of the review\n",
    "date_posted = card.find_element(By.XPATH , './/div[@class=\"apphub_CardTextContent\"]/div').text\n",
    "review_content = card.find_element(By.XPATH , './/div[@class=\"apphub_CardTextContent\"]').text.replace(date_posted,'').strip()    \n",
    "    \n",
    "\n",
    "        # recommendation\n",
    "thumb_text = card.find_element(By.XPATH , './/div[@class=\"reviewInfo\"]/div[2]').text\n",
    "thumb_text    \n",
    "\n",
    "        # amount of play hours\n",
    "play_hours = card.find_element( By.XPATH , './/div[@class=\"reviewInfo\"]/div[3]').text\n",
    "play_hours    \n",
    "\n",
    "        # save review\n",
    "review = (steam_id, profile_url, review_content, thumb_text, review_length, play_hours, date_posted)\n",
    "reviews.append(review)    \n",
    "        \n",
    "    # attempt to scroll down thrice.. then break\n",
    "scroll_attempt = 0\n",
    "while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")    \n",
    "        sleep(0.5)\n",
    "        curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "        \n",
    "        if curr_position == last_position: scroll_attempt += 1\n",
    "        sleep(0.5)\n",
    "            \n",
    "        if curr_position >= 3:\n",
    "                running = False\n",
    "                break\n",
    "        else:\n",
    "            last_position = curr_position\n",
    "            break  # continue scraping the results\n",
    "\n",
    "# shutdown the web driver\n",
    "driver.close()\n",
    "\n",
    "today = datetime.today().strftime('%Y%m%d')   \n",
    "with open(f'Steam_Reviews_{game_id}_{today}.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['SteamId', 'ProfileURL', 'ReviewText', 'Review', 'ReviewLength(Chars)', 'PlayHours', 'DatePosted'])\n",
    "    writer.writerows(reviews)\n",
    "    writer.close(reviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
